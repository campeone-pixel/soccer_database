{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ojo7lukxLotg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlGQeaxoLotn",
        "outputId": "c45aa762-722f-4625-f71c-a1e447e0bd3a"
      },
      "outputs": [],
      "source": [
        "lista_ligas = [\n",
        "    \"https://fbref.com/en/comps/12/2021-2022/2021-2022-La-Liga-Stats\",\n",
        "    \"https://fbref.com/en/comps/9/2021-2022/2021-2022-Premier-League-Stats\",\n",
        "    \"https://fbref.com/en/comps/11/2021-2022/2021-2022-Serie-A-Stats\",\n",
        "    \"https://fbref.com/en/comps/13/2021-2022/2021-2022-Ligue-1-Stats\",\n",
        "    \"https://fbref.com/en/comps/20/2021-2022/2021-2022-Bundesliga-Stats\",\n",
        "]\n",
        "\n",
        "years = list(range(2021, 2013, -1))\n",
        "all_matches = []\n",
        "log_error = []\n",
        "log = []\n",
        "for year in years:\n",
        "    for indice, liga in enumerate(lista_ligas):\n",
        "        data = requests.get(liga)\n",
        "        soup = BeautifulSoup(data.text)\n",
        "\n",
        "        try:\n",
        "            standings_table = soup.select(\"table.stats_table\")[0]\n",
        "        except Exception as e:\n",
        "            \n",
        "            continue\n",
        "\n",
        "        links = [l.get(\"href\") for l in standings_table.find_all(\"a\")]\n",
        "        links = [l for l in links if \"/squads/\" in l]\n",
        "        team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
        "\n",
        "        previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n",
        "        \n",
        "\n",
        "        time.sleep(1)\n",
        "        for team_url in team_urls:\n",
        "            \n",
        "            team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
        "            data = requests.get(team_url)\n",
        "            time.sleep(1)\n",
        "            try:\n",
        "                matches = pd.read_html(data.text, match=\"Scores & Fixtures\")[0]\n",
        "                matches = matches[\n",
        "                    [\n",
        "                        \"Date\",\n",
        "                        \"Time\",\n",
        "                        \"Comp\",\n",
        "                        \"Round\",\n",
        "                        \"Venue\",\n",
        "                        \"Result\",\n",
        "                        \"GF\",\n",
        "                        \"GA\",\n",
        "                        \"Opponent\",\n",
        "                        \"Poss\",\n",
        "                        \"Formation\",\n",
        "                    ]\n",
        "                ]\n",
        "                soup = BeautifulSoup(data.text)\n",
        "                links = [l.get(\"href\") for l in soup.find_all(\"a\")]\n",
        "                time.sleep(1)\n",
        "            except Exception as e:\n",
        "                log_error.append(f\"error:{e},{lista_ligas[indice]},{team_url}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                links_shooting = [l for l in links if l and \"all_comps/shooting/\" in l]\n",
        "                data_shooting = requests.get(f\"https://fbref.com{links_shooting[0]}\")\n",
        "                shooting = pd.read_html(data_shooting.text, match=\"Shooting\")[0]\n",
        "                shooting.columns = shooting.columns.droplevel()\n",
        "                time.sleep(1)\n",
        "            except Exception as e:\n",
        "                \n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                links_misc = [l for l in links if l and \"all_comps/misc/\" in l]\n",
        "                data_misc = requests.get(f\"https://fbref.com{links_misc[0]}\")\n",
        "                defensive = pd.read_html(data_misc.text, match=\"Miscellaneous Stats\")[0]\n",
        "                defensive.columns = defensive.columns.droplevel()\n",
        "                time.sleep(1)\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                team_data = matches.merge(defensive[[\"Date\", \"TklW\", \"Int\"]], on=\"Date\")\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "            try: \n",
        "                if 'xG' in shooting.columns:\n",
        "                    team_data = team_data.merge(\n",
        "                    shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"PK\", \"PKatt\", \"xG\"]],\n",
        "                        on=\"Date\",\n",
        "                    )\n",
        "                    print('entre en el if')\n",
        "                    print(shooting.columns)\n",
        "                else:\n",
        "                    shooting[\"xG\"] = ''\n",
        "                    team_data = team_data.merge(\n",
        "                    shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"PK\", \"PKatt\", \"xG\"]], on=\"Date\"\n",
        "                )\n",
        "                    print('entre en el else')\n",
        "                    print(shooting.columns)\n",
        "\n",
        "            except Exception as e:\n",
        "              \n",
        "                continue\n",
        "\n",
        "            team_data[\"Season\"] = year\n",
        "            team_data[\"Team\"] = team_name\n",
        "            all_matches.append(team_data)\n",
        "            time.sleep(2)\n",
        "            pass\n",
        "\n",
        "        lista_ligas[indice] = f\"https://fbref.com{previous_season}\"\n",
        "     \n",
        "\n",
        "match_df = pd.concat(all_matches)\n",
        "match_df.columns = [c.lower() for c in match_df.columns]\n",
        "match_df = match_df[['date', 'time', 'season', 'team', 'comp', 'round', 'venue', 'result', 'gf', 'ga',\n",
        "       'opponent', 'poss', 'formation', 'tklw', 'int', 'sh', 'sot', 'dist',\n",
        "       'pk', 'pkatt', 'xg']]\n",
        "match_df.to_csv('matches.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0f7c5ce30e5f0d7cc845aa124c9e975c020ec21fe98e4a7c7b29adf0872a8c47"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
